

Training Steps: 1000
Train Loss: 0.000139929, averaged to 8.75652847854e-08
Test Loss: 5.84688e-05, averaged to 9.64831901355e-08


Training Steps: 2000
Train Loss: 0.000139929, averaged to 8.75652847854e-08
Test Loss: 5.84688e-05, averaged to 9.64831901355e-08


Training Steps: 3000
Train Loss: 0.000138852, averaged to 8.6890933735e-08
Test Loss: 5.82362e-05, averaged to 9.60993473518e-08


Training Steps: 4000
Train Loss: 0.000138852, averaged to 8.6890933735e-08
Test Loss: 5.82362e-05, averaged to 9.60993473518e-08


Training Steps: 5000
Train Loss: 0.000138852, averaged to 8.6890933735e-08
Test Loss: 5.82362e-05, averaged to 9.60993473518e-08


Training Steps: 6000
Train Loss: 0.000138852, averaged to 8.6890933735e-08
Test Loss: 5.82362e-05, averaged to 9.60993473518e-08


Training Steps: 7000
Train Loss: 0.000138576, averaged to 8.67185782284e-08
Test Loss: 5.8176e-05, averaged to 9.60000773558e-08


Training Steps: 8000
Train Loss: 0.000138457, averaged to 8.6643933642e-08
Test Loss: 5.83535e-05, averaged to 9.62928566074e-08


Training Steps: 9000
Train Loss: 0.000138457, averaged to 8.6643933642e-08
Test Loss: 5.83535e-05, averaged to 9.62928566074e-08


Training Steps: 10000
Train Loss: 0.000138393, averaged to 8.6603856684e-08
Test Loss: 5.85164e-05, averaged to 9.65617068432e-08


Training Steps: 11000
Train Loss: 0.000138337, averaged to 8.65685241239e-08
Test Loss: 5.85828e-05, averaged to 9.66713024555e-08


Training Steps: 12000
Train Loss: 0.000138329, averaged to 8.65635975994e-08
Test Loss: 5.8649e-05, averaged to 9.67806039079e-08


Training Steps: 13000
Train Loss: 0.000138329, averaged to 8.65635975994e-08
Test Loss: 5.8649e-05, averaged to 9.67806039079e-08


Training Steps: 14000
Train Loss: 0.00013821, averaged to 8.64890805016e-08
Test Loss: 5.85848e-05, averaged to 9.66745502221e-08


Training Steps: 15000
Train Loss: 0.000138093, averaged to 8.64161752241e-08
Test Loss: 5.83899e-05, averaged to 9.63529613001e-08


Training Steps: 16000
Train Loss: 0.000138087, averaged to 8.64121593326e-08
Test Loss: 5.83503e-05, averaged to 9.62876998024e-08


Training Steps: 17000
Train Loss: 0.000138086, averaged to 8.64114763579e-08
Test Loss: 5.83431e-05, averaged to 9.62756932717e-08


Training Steps: 18000
Train Loss: 0.000137749, averaged to 8.6200582863e-08
Test Loss: 5.78909e-05, averaged to 9.55295714334e-08


Training Steps: 19000
Train Loss: 0.000137741, averaged to 8.61960479107e-08
Test Loss: 5.78611e-05, averaged to 9.54804106934e-08


Training Steps: 20000
Train Loss: 0.000137741, averaged to 8.61959659538e-08
Test Loss: 5.78552e-05, averaged to 9.54705893512e-08


Training Steps: 21000
Train Loss: 0.000137376, averaged to 8.59675609865e-08
Test Loss: 5.78193e-05, averaged to 9.54113071058e-08


Training Steps: 22000
Train Loss: 0.000137336, averaged to 8.59425823235e-08
Test Loss: 5.78502e-05, averaged to 9.54623528712e-08


Training Steps: 23000
Train Loss: 0.000137329, averaged to 8.59378106066e-08
Test Loss: 5.78523e-05, averaged to 9.54658347651e-08


Training Steps: 24000
Train Loss: 0.0001373, averaged to 8.59198711366e-08
Test Loss: 5.78206e-05, averaged to 9.54134982977e-08


Training Steps: 25000
Train Loss: 0.000137279, averaged to 8.59065394696e-08
Test Loss: 5.77943e-05, averaged to 9.53701847381e-08


Training Steps: 26000
Train Loss: 0.000137277, averaged to 8.5905419391e-08
Test Loss: 5.7778e-05, averaged to 9.53432240734e-08


Training Steps: 27000
Train Loss: 0.000137116, averaged to 8.58047398073e-08
Test Loss: 5.79616e-05, averaged to 9.56462388924e-08


Training Steps: 28000
Train Loss: 0.000136876, averaged to 8.56544580445e-08
Test Loss: 5.79854e-05, averaged to 9.56854942445e-08


Training Steps: 29000
Train Loss: 0.000136675, averaged to 8.5529027456e-08
Test Loss: 5.79357e-05, averaged to 9.56034296071e-08


Training Steps: 30000
Train Loss: 0.00013649, averaged to 8.54127123038e-08
Test Loss: 5.7882e-05, averaged to 9.55147913941e-08


Training Steps: 31000
Train Loss: 0.000136316, averaged to 8.53044016156e-08
Test Loss: 5.78288e-05, averaged to 9.54270536709e-08


Training Steps: 32000
Train Loss: 0.000136155, averaged to 8.52034852673e-08
Test Loss: 5.77783e-05, averaged to 9.53437463575e-08


Training Steps: 33000
Train Loss: 0.000135965, averaged to 8.50842196642e-08
Test Loss: 5.77514e-05, averaged to 9.52994062395e-08


Training Steps: 34000
Train Loss: 0.000135741, averaged to 8.49444010745e-08
Test Loss: 5.77642e-05, averaged to 9.5320387652e-08


Training Steps: 35000
Train Loss: 0.000135467, averaged to 8.47728833503e-08
Test Loss: 5.76157e-05, averaged to 9.507533436e-08


Training Steps: 36000
Train Loss: 0.000135251, averaged to 8.46376088191e-08
Test Loss: 5.74906e-05, averaged to 9.48689961264e-08


Training Steps: 37000
Train Loss: 0.000135075, averaged to 8.45276407789e-08
Test Loss: 5.73959e-05, averaged to 9.47126410802e-08


Training Steps: 38000
Train Loss: 0.000134929, averaged to 8.44359855682e-08
Test Loss: 5.73265e-05, averaged to 9.45982248457e-08


Training Steps: 39000
Train Loss: 0.000134804, averaged to 8.43578896827e-08
Test Loss: 5.72747e-05, averaged to 9.45127803699e-08


Training Steps: 40000
Train Loss: 0.000134695, averaged to 8.42900202057e-08
Test Loss: 5.72366e-05, averaged to 9.44498481391e-08


Training Steps: 41000
Train Loss: 0.0001346, averaged to 8.42301916181e-08
Test Loss: 5.72081e-05, averaged to 9.44028785909e-08


Training Steps: 42000
Train Loss: 0.000134514, averaged to 8.41766828234e-08
Test Loss: 5.71858e-05, averaged to 9.43660185416e-08


Training Steps: 43000
Train Loss: 0.000134437, averaged to 8.41284101684e-08
Test Loss: 5.71693e-05, averaged to 9.43388537659e-08


Training Steps: 44000
Train Loss: 0.000134367, averaged to 8.4084180724e-08
Test Loss: 5.7156e-05, averaged to 9.4316797769e-08


Training Steps: 45000
Train Loss: 0.000134302, averaged to 8.40437121938e-08
Test Loss: 5.71455e-05, averaged to 9.42995323778e-08


Training Steps: 46000
Train Loss: 0.000134243, averaged to 8.40067496006e-08
Test Loss: 5.71362e-05, averaged to 9.42842360577e-08


Training Steps: 47000
Train Loss: 0.000134188, averaged to 8.39726828203e-08
Test Loss: 5.71283e-05, averaged to 9.42711369327e-08


Training Steps: 48000
Train Loss: 0.000134138, averaged to 8.39411475998e-08
Test Loss: 5.71217e-05, averaged to 9.42601929799e-08


Training Steps: 49000
Train Loss: 0.000134091, averaged to 8.39119344933e-08
Test Loss: 5.71164e-05, averaged to 9.42514282125e-08


Training Steps: 50000
Train Loss: 0.000134048, averaged to 8.38848158428e-08
Test Loss: 5.71115e-05, averaged to 9.42434258598e-08


Training Steps: 51000
Train Loss: 0.000134008, averaged to 8.38596095216e-08
Test Loss: 5.71075e-05, averaged to 9.42367322189e-08


Training Steps: 52000
Train Loss: 0.00013397, averaged to 8.38361698283e-08
Test Loss: 5.71037e-05, averaged to 9.42305548588e-08


Training Steps: 53000
Train Loss: 0.000133935, averaged to 8.38143601681e-08
Test Loss: 5.71e-05, averaged to 9.42244255249e-08


Training Steps: 54000
Train Loss: 0.000133872, averaged to 8.3774501762e-08
Test Loss: 5.70887e-05, averaged to 9.42057613729e-08


Training Steps: 55000
Train Loss: 0.000133749, averaged to 8.36980268033e-08
Test Loss: 5.70924e-05, averaged to 9.42119267264e-08


Training Steps: 56000
Train Loss: 0.000133645, averaged to 8.36324430151e-08
Test Loss: 5.70915e-05, averaged to 9.4210377884e-08


Training Steps: 57000
Train Loss: 0.000133559, averaged to 8.35789706458e-08
Test Loss: 5.70718e-05, averaged to 9.41779062216e-08


Training Steps: 58000
Train Loss: 0.000133488, averaged to 8.35341948215e-08
Test Loss: 5.70564e-05, averaged to 9.41524943994e-08


Training Steps: 59000
Train Loss: 0.000133427, averaged to 8.34959664485e-08
Test Loss: 5.70439e-05, averaged to 9.41319031992e-08


Training Steps: 60000
Train Loss: 0.000133374, averaged to 8.34627920885e-08
Test Loss: 5.70344e-05, averaged to 9.41162166668e-08


Training Steps: 61000
Train Loss: 0.000133329, averaged to 8.34348629746e-08
Test Loss: 5.70297e-05, averaged to 9.41084364349e-08


Training Steps: 62000
Train Loss: 0.00013329, averaged to 8.34106765623e-08
Test Loss: 5.70274e-05, averaged to 9.41046423712e-08


Training Steps: 63000
Train Loss: 0.000133256, averaged to 8.33895225579e-08
Test Loss: 5.70264e-05, averaged to 9.41029914732e-08


Training Steps: 64000
Train Loss: 0.000133204, averaged to 8.33568854714e-08
Test Loss: 5.70218e-05, averaged to 9.40953733295e-08


Training Steps: 65000
Train Loss: 0.000133156, averaged to 8.33269347523e-08
Test Loss: 5.70204e-05, averaged to 9.40930980919e-08


Training Steps: 66000
Train Loss: 0.000133115, averaged to 8.33012366892e-08
Test Loss: 5.702e-05, averaged to 9.40923777001e-08


Training Steps: 67000
Train Loss: 0.000133081, averaged to 8.32795727303e-08
Test Loss: 5.70211e-05, averaged to 9.4094298745e-08


Training Steps: 68000
Train Loss: 0.00013305, averaged to 8.32606133514e-08
Test Loss: 5.70235e-05, averaged to 9.40982008675e-08


Training Steps: 69000
Train Loss: 0.000133024, averaged to 8.3243766641e-08
Test Loss: 5.70264e-05, averaged to 9.4103009483e-08


Training Steps: 70000
Train Loss: 0.000132999, averaged to 8.3228668346e-08
Test Loss: 5.703e-05, averaged to 9.41089046896e-08


Training Steps: 71000
Train Loss: 0.000132977, averaged to 8.32149451068e-08
Test Loss: 5.70334e-05, averaged to 9.41145537623e-08


Training Steps: 72000
Train Loss: 0.000132958, averaged to 8.32024967538e-08
Test Loss: 5.70347e-05, averaged to 9.41166849215e-08


Training Steps: 73000
Train Loss: 0.00013294, averaged to 8.31912322237e-08
Test Loss: 5.70363e-05, averaged to 9.41193023452e-08


Training Steps: 74000
Train Loss: 0.000132923, averaged to 8.31807872632e-08
Test Loss: 5.70381e-05, averaged to 9.4122261955e-08


Training Steps: 75000
Train Loss: 0.000132907, averaged to 8.31710343839e-08
Test Loss: 5.70397e-05, averaged to 9.41249634245e-08


Training Steps: 76000
Train Loss: 0.000132893, averaged to 8.31618369907e-08
Test Loss: 5.70415e-05, averaged to 9.41278209788e-08


Training Steps: 77000
Train Loss: 0.000132879, averaged to 8.31531040203e-08
Test Loss: 5.70428e-05, averaged to 9.41300962163e-08


Training Steps: 78000
Train Loss: 0.000132865, averaged to 8.31447717284e-08
Test Loss: 5.70437e-05, averaged to 9.41314949772e-08


Training Steps: 79000
Train Loss: 0.000132853, averaged to 8.3136812796e-08
Test Loss: 5.70446e-05, averaged to 9.41329237543e-08


Training Steps: 80000
Train Loss: 0.00013284, averaged to 8.31292090105e-08
Test Loss: 5.70453e-05, averaged to 9.41341304107e-08


Training Steps: 81000
Train Loss: 0.000132829, averaged to 8.31219057339e-08
Test Loss: 5.70456e-05, averaged to 9.41345866588e-08


Training Steps: 82000
Train Loss: 0.000132818, averaged to 8.31149029662e-08
Test Loss: 5.7046e-05, averaged to 9.41353070507e-08


Training Steps: 83000
Train Loss: 0.000132807, averaged to 8.31082007074e-08
Test Loss: 5.70464e-05, averaged to 9.41359974262e-08


Training Steps: 84000
Train Loss: 0.000132615, averaged to 8.29880608966e-08
Test Loss: 5.71754e-05, averaged to 9.43488011766e-08


Training Steps: 85000
Train Loss: 0.000132555, averaged to 8.29504699667e-08
Test Loss: 5.72201e-05, averaged to 9.44225632981e-08


Training Steps: 86000
Train Loss: 0.000132509, averaged to 8.29218760907e-08
Test Loss: 5.72436e-05, averaged to 9.4461452451e-08


Training Steps: 87000
Train Loss: 0.000132432, averaged to 8.2873803775e-08
Test Loss: 5.72921e-05, averaged to 9.45414099424e-08


Training Steps: 88000
Train Loss: 0.000132396, averaged to 8.28511381198e-08
Test Loss: 5.73502e-05, averaged to 9.4637324113e-08


Training Steps: 89000
Train Loss: 0.00013237, averaged to 8.28350472348e-08
Test Loss: 5.73815e-05, averaged to 9.46889041689e-08


Training Steps: 90000
Train Loss: 0.000132349, averaged to 8.2821915907e-08
Test Loss: 5.74034e-05, averaged to 9.47251578884e-08


Training Steps: 91000
Train Loss: 0.000132332, averaged to 8.28107697592e-08
Test Loss: 5.7422e-05, averaged to 9.47557745418e-08


Training Steps: 92000
Train Loss: 0.000132316, averaged to 8.28009986672e-08
Test Loss: 5.74385e-05, averaged to 9.47830113567e-08


Training Steps: 93000
Train Loss: 0.000132302, averaged to 8.27923567601e-08
Test Loss: 5.74526e-05, averaged to 9.48063460491e-08


Training Steps: 94000
Train Loss: 0.000132138, averaged to 8.26895827205e-08
Test Loss: 5.72487e-05, averaged to 9.44697789801e-08


Training Steps: 95000
Train Loss: 0.00013206, averaged to 8.26407363667e-08
Test Loss: 5.72092e-05, averaged to 9.44046075314e-08


Training Steps: 96000
Train Loss: 0.000132001, averaged to 8.26038284115e-08
Test Loss: 5.72003e-05, averaged to 9.43899955835e-08


Training Steps: 97000
Train Loss: 0.000131947, averaged to 8.25702442668e-08
Test Loss: 5.71971e-05, averaged to 9.43845986479e-08


Training Steps: 98000
Train Loss: 0.000131896, averaged to 8.25383538993e-08
Test Loss: 5.71947e-05, averaged to 9.43806244863e-08


Training Steps: 99000
Train Loss: 0.000131847, averaged to 8.25077202055e-08
Test Loss: 5.71938e-05, averaged to 9.4379237732e-08


Training Steps: 100000
Train Loss: 0.0001318, averaged to 8.24782612281e-08
Test Loss: 5.7193e-05, averaged to 9.43778149581e-08


Training Steps: 101000
Train Loss: 0.000131728, averaged to 8.24329025987e-08
Test Loss: 5.71334e-05, averaged to 9.42796015368e-08


Training Steps: 102000
Train Loss: 0.00013161, averaged to 8.23590593693e-08
Test Loss: 5.71161e-05, averaged to 9.42510019806e-08


Training Steps: 103000
Train Loss: 0.000131502, averaged to 8.22915632519e-08
Test Loss: 5.71562e-05, averaged to 9.43171339518e-08


Training Steps: 104000
Train Loss: 0.000131401, averaged to 8.22285838741e-08
Test Loss: 5.72043e-05, averaged to 9.43965091264e-08


Training Steps: 105000
Train Loss: 0.000131307, averaged to 8.21696294941e-08
Test Loss: 5.72543e-05, averaged to 9.44790120022e-08


Training Steps: 106000
Train Loss: 0.000131219, averaged to 8.21143813905e-08
Test Loss: 5.73055e-05, averaged to 9.45635739981e-08


Training Steps: 107000
Train Loss: 0.00013114, averaged to 8.20652254215e-08
Test Loss: 5.74082e-05, averaged to 9.47330041563e-08


Training Steps: 108000
Train Loss: 0.000130978, averaged to 8.19637626934e-08
Test Loss: 5.75736e-05, averaged to 9.50059606256e-08


Training Steps: 109000
Train Loss: 0.000130895, averaged to 8.19119112508e-08
Test Loss: 5.77384e-05, averaged to 9.52778124941e-08


Training Steps: 110000
Train Loss: 0.000130828, averaged to 8.18699674951e-08
Test Loss: 5.78676e-05, averaged to 9.54910604861e-08


Training Steps: 111000
Train Loss: 0.00013077, averaged to 8.18334693248e-08
Test Loss: 5.79846e-05, averaged to 9.56841134935e-08


Training Steps: 112000
Train Loss: 0.000130718, averaged to 8.18012329168e-08
Test Loss: 5.80927e-05, averaged to 9.58626085824e-08


Training Steps: 113000
Train Loss: 0.000130672, averaged to 8.17723294256e-08
Test Loss: 5.81921e-05, averaged to 9.60265937789e-08


Training Steps: 114000
Train Loss: 0.000130631, averaged to 8.17462944283e-08
Test Loss: 5.82838e-05, averaged to 9.61778520529e-08


Training Steps: 115000
Train Loss: 0.000130593, averaged to 8.17225815452e-08
Test Loss: 5.83683e-05, averaged to 9.63172838941e-08


Training Steps: 116000
Train Loss: 0.000130558, averaged to 8.1700853842e-08
Test Loss: 5.84457e-05, averaged to 9.64450874103e-08


Training Steps: 117000
Train Loss: 0.000130526, averaged to 8.16808836605e-08
Test Loss: 5.85173e-05, averaged to 9.65632376758e-08


Training Steps: 118000
Train Loss: 0.000130496, averaged to 8.16623704917e-08
Test Loss: 5.85832e-05, averaged to 9.66719388017e-08


Training Steps: 119000
Train Loss: 0.000130469, averaged to 8.16451959535e-08
Test Loss: 5.86435e-05, averaged to 9.6771442925e-08


Training Steps: 120000
Train Loss: 0.000130443, averaged to 8.16291506001e-08
Test Loss: 5.86989e-05, averaged to 9.68628846629e-08


Training Steps: 121000
Train Loss: 0.000130419, averaged to 8.16140887304e-08
Test Loss: 5.87508e-05, averaged to 9.69484912269e-08


Training Steps: 122000
Train Loss: 0.000130397, averaged to 8.1599973919e-08
Test Loss: 5.87978e-05, averaged to 9.70261314578e-08


Training Steps: 123000
Train Loss: 0.000130375, averaged to 8.1586614933e-08
Test Loss: 5.88415e-05, averaged to 9.70981646388e-08


Training Steps: 124000
Train Loss: 0.000130355, averaged to 8.15740937294e-08
Test Loss: 5.8882e-05, averaged to 9.7165089041e-08


Training Steps: 125000
Train Loss: 0.000130336, averaged to 8.15622372878e-08
Test Loss: 5.89193e-05, averaged to 9.72265384653e-08


Training Steps: 126000
Train Loss: 0.000130318, averaged to 8.1550954545e-08
Test Loss: 5.89543e-05, averaged to 9.72843198943e-08


Training Steps: 127000
Train Loss: 0.000130302, averaged to 8.15403638833e-08
Test Loss: 5.89864e-05, averaged to 9.73373167209e-08


Training Steps: 128000
Train Loss: 0.000130285, averaged to 8.15302103254e-08
Test Loss: 5.90161e-05, averaged to 9.73863093695e-08


Training Steps: 129000
Train Loss: 0.00013027, averaged to 8.15205758284e-08
Test Loss: 5.90443e-05, averaged to 9.7432810663e-08


Training Steps: 130000
Train Loss: 0.000130255, averaged to 8.15114148605e-08
Test Loss: 5.90699e-05, averaged to 9.74750796544e-08


Training Steps: 131000
Train Loss: 0.000130241, averaged to 8.15026636774e-08
Test Loss: 5.90941e-05, averaged to 9.75150193788e-08


Training Steps: 132000
Train Loss: 0.000130228, averaged to 8.14943131728e-08
Test Loss: 5.91172e-05, averaged to 9.7553122104e-08


Training Steps: 133000
Train Loss: 0.000130215, averaged to 8.14863542405e-08
Test Loss: 5.91386e-05, averaged to 9.7588481337e-08


Training Steps: 134000
Train Loss: 0.000130203, averaged to 8.14787322423e-08
Test Loss: 5.91588e-05, averaged to 9.76217754466e-08


Training Steps: 135000
Train Loss: 0.000130191, averaged to 8.14714653911e-08
Test Loss: 5.91772e-05, averaged to 9.76521759824e-08


Training Steps: 136000
Train Loss: 0.00013018, averaged to 8.1464480836e-08
Test Loss: 5.9195e-05, averaged to 9.76814539076e-08


Training Steps: 137000
Train Loss: 0.00013017, averaged to 8.14577876835e-08
Test Loss: 5.92118e-05, averaged to 9.7709176987e-08


Training Steps: 138000
Train Loss: 0.000130159, averaged to 8.14514223589e-08
Test Loss: 5.92275e-05, averaged to 9.77351170966e-08


Training Steps: 139000
Train Loss: 0.000130057, averaged to 8.13870861379e-08
Test Loss: 5.88163e-05, averaged to 9.70566640654e-08


Training Steps: 140000
Train Loss: 0.000129998, averaged to 8.13505060106e-08
Test Loss: 5.85946e-05, averaged to 9.66907710451e-08


Training Steps: 141000
Train Loss: 0.000129966, averaged to 8.13306542113e-08
Test Loss: 5.86012e-05, averaged to 9.67016609685e-08


Training Steps: 142000
Train Loss: 0.000129938, averaged to 8.13130789946e-08
Test Loss: 5.86394e-05, averaged to 9.67646592351e-08


Training Steps: 143000
Train Loss: 0.000129912, averaged to 8.129688794e-08
Test Loss: 5.86827e-05, averaged to 9.68362121549e-08


Training Steps: 144000
Train Loss: 0.000129888, averaged to 8.12818169639e-08
Test Loss: 5.87277e-05, averaged to 9.69103764952e-08


Training Steps: 145000
Train Loss: 0.000129866, averaged to 8.12678205348e-08
Test Loss: 5.87722e-05, averaged to 9.69838504599e-08


Training Steps: 146000
Train Loss: 0.000129845, averaged to 8.12547347387e-08
Test Loss: 5.88172e-05, averaged to 9.70581348654e-08


Training Steps: 147000
Train Loss: 0.000129825, averaged to 8.12423956617e-08
Test Loss: 5.88612e-05, averaged to 9.71306182914e-08


Training Steps: 148000
Train Loss: 0.000129807, averaged to 8.12308488353e-08
Test Loss: 5.89047e-05, averaged to 9.72024713744e-08


Training Steps: 149000
Train Loss: 0.00012979, averaged to 8.12200031964e-08
Test Loss: 5.89472e-05, averaged to 9.72726075236e-08


Training Steps: 150000
Train Loss: 0.000129773, averaged to 8.12098041068e-08
Test Loss: 5.8989e-05, averaged to 9.73415850426e-08


Training Steps: 151000
Train Loss: 0.000129758, averaged to 8.12001605034e-08
Test Loss: 5.90293e-05, averaged to 9.74080772097e-08


Training Steps: 152000
Train Loss: 0.000129743, averaged to 8.11911088115e-08
Test Loss: 5.90697e-05, averaged to 9.74748095074e-08


Training Steps: 153000
Train Loss: 0.00012973, averaged to 8.11825761803e-08
Test Loss: 5.91085e-05, averaged to 9.75387382802e-08


Training Steps: 154000
Train Loss: 0.000129717, averaged to 8.1174644567e-08
Test Loss: 5.91476e-05, averaged to 9.76033154057e-08


Training Steps: 155000
Train Loss: 0.000129705, averaged to 8.11671955891e-08
Test Loss: 5.91857e-05, averaged to 9.76661755972e-08


Training Steps: 156000
Train Loss: 0.000129694, averaged to 8.11601563961e-08
Test Loss: 5.92233e-05, averaged to 9.77282793774e-08


Training Steps: 157000
Train Loss: 0.000129683, averaged to 8.11534723499e-08
Test Loss: 5.92596e-05, averaged to 9.77880899101e-08


Training Steps: 158000
Train Loss: 0.000129673, averaged to 8.11471798759e-08
Test Loss: 5.92947e-05, averaged to 9.78460634437e-08


Training Steps: 159000
Train Loss: 0.000129664, averaged to 8.11412152298e-08
Test Loss: 5.93291e-05, averaged to 9.79028483307e-08


Training Steps: 160000
Train Loss: 0.000129655, averaged to 8.11355784116e-08
Test Loss: 5.93631e-05, averaged to 9.79589188292e-08


Training Steps: 161000
Train Loss: 0.000129646, averaged to 8.11302603149e-08
Test Loss: 5.93961e-05, averaged to 9.80134104688e-08


Training Steps: 162000
Train Loss: 0.000129638, averaged to 8.11251516638e-08
Test Loss: 5.94288e-05, averaged to 9.80673077852e-08


Training Steps: 163000
Train Loss: 0.00012963, averaged to 8.11203890533e-08
Test Loss: 5.94605e-05, averaged to 9.81195602069e-08


Training Steps: 164000
Train Loss: 0.000129623, averaged to 8.1115826782e-08
Test Loss: 5.94906e-05, averaged to 9.816933328e-08


Training Steps: 165000
Train Loss: 0.000129616, averaged to 8.11115468069e-08
Test Loss: 5.95203e-05, averaged to 9.82182839057e-08


Training Steps: 166000
Train Loss: 0.00012961, averaged to 8.11074762774e-08
Test Loss: 5.95487e-05, averaged to 9.82651574016e-08


Training Steps: 167000
Train Loss: 0.000129603, averaged to 8.11035605555e-08
Test Loss: 5.95767e-05, averaged to 9.83113465253e-08


Training Steps: 168000
Train Loss: 0.000129598, averaged to 8.10998360666e-08
Test Loss: 5.96044e-05, averaged to 9.83570553877e-08


Training Steps: 169000
Train Loss: 0.000129592, averaged to 8.10963574486e-08
Test Loss: 5.96309e-05, averaged to 9.8400837202e-08


Training Steps: 170000
Train Loss: 0.000129587, averaged to 8.10930609571e-08
Test Loss: 5.96568e-05, averaged to 9.84435324252e-08


Training Steps: 171000
Train Loss: 0.000129582, averaged to 8.1089882848e-08
Test Loss: 5.9682e-05, averaged to 9.84851050378e-08


Training Steps: 172000
Train Loss: 0.000129577, averaged to 8.10868595465e-08
Test Loss: 5.97059e-05, averaged to 9.85246665565e-08


Training Steps: 173000
Train Loss: 0.000129572, averaged to 8.10840183715e-08
Test Loss: 5.97295e-05, averaged to 9.85635376997e-08


Training Steps: 174000
Train Loss: 0.000129568, averaged to 8.10813046852e-08
Test Loss: 5.97524e-05, averaged to 9.86013522682e-08


Training Steps: 175000
Train Loss: 0.000129564, averaged to 8.10786820622e-08
Test Loss: 5.97747e-05, averaged to 9.86380982555e-08


Training Steps: 176000
Train Loss: 0.00012956, averaged to 8.10761869278e-08
Test Loss: 5.97967e-05, averaged to 9.8674466037e-08


Training Steps: 177000
Train Loss: 0.000129556, averaged to 8.10738648136e-08
Test Loss: 5.98179e-05, averaged to 9.87094830838e-08


Training Steps: 178000
Train Loss: 0.000129552, averaged to 8.10716519755e-08
Test Loss: 5.98391e-05, averaged to 9.87443440458e-08


Training Steps: 179000
Train Loss: 0.000129549, averaged to 8.10694755626e-08
Test Loss: 5.98587e-05, averaged to 9.87767976983e-08


Training Steps: 180000
Train Loss: 0.000129546, averaged to 8.10674266384e-08
Test Loss: 5.98786e-05, averaged to 9.88096415631e-08


Training Steps: 181000
Train Loss: 0.000129543, averaged to 8.10655143091e-08
Test Loss: 5.98971e-05, averaged to 9.88401681674e-08


Training Steps: 182000
Train Loss: 0.00012954, averaged to 8.10636566178e-08
Test Loss: 5.99158e-05, averaged to 9.88708748697e-08


Training Steps: 183000
Train Loss: 0.000129537, averaged to 8.10618262455e-08
Test Loss: 5.9934e-05, averaged to 9.89009392226e-08


Training Steps: 184000
Train Loss: 0.000129534, averaged to 8.10601597871e-08
Test Loss: 5.99508e-05, averaged to 9.89287583543e-08


Training Steps: 185000
Train Loss: 0.000129531, averaged to 8.10584842224e-08
Test Loss: 5.99674e-05, averaged to 9.89560311888e-08


Training Steps: 186000
Train Loss: 0.000129529, averaged to 8.1056899721e-08
Test Loss: 5.99829e-05, averaged to 9.89817491776e-08


Training Steps: 187000
Train Loss: 0.000129527, averaged to 8.10554427082e-08
Test Loss: 5.99985e-05, averaged to 9.90074551599e-08


Training Steps: 188000
Train Loss: 0.000129524, averaged to 8.10539765891e-08
Test Loss: 6.00144e-05, averaged to 9.90336474067e-08


Training Steps: 189000
Train Loss: 0.000129522, averaged to 8.10526470649e-08
Test Loss: 6.0029e-05, averaged to 9.90578105497e-08


Training Steps: 190000
Train Loss: 0.00012952, averaged to 8.10513448597e-08
Test Loss: 6.00433e-05, averaged to 9.90813313434e-08


Training Steps: 191000
Train Loss: 0.000129518, averaged to 8.10500972925e-08
Test Loss: 6.00576e-05, averaged to 9.91050202285e-08


Training Steps: 192000
Train Loss: 0.000129516, averaged to 8.10488588317e-08
Test Loss: 6.00708e-05, averaged to 9.91267520491e-08


Training Steps: 193000
Train Loss: 0.000129514, averaged to 8.10477023278e-08
Test Loss: 6.0084e-05, averaged to 9.91485258926e-08


Training Steps: 194000
Train Loss: 0.000129512, averaged to 8.10465822492e-08
Test Loss: 6.00974e-05, averaged to 9.9170593896e-08


Training Steps: 195000
Train Loss: 0.000129511, averaged to 8.10455168086e-08
Test Loss: 6.01098e-05, averaged to 9.91910410178e-08


Training Steps: 196000
Train Loss: 0.000129509, averaged to 8.10444968996e-08
Test Loss: 6.01216e-05, averaged to 9.92105576335e-08


Training Steps: 197000
Train Loss: 0.000129508, averaged to 8.10435316286e-08
Test Loss: 6.01333e-05, averaged to 9.92298341186e-08


Training Steps: 198000
Train Loss: 0.000129506, averaged to 8.10425936767e-08
Test Loss: 6.01448e-05, averaged to 9.92488224469e-08


Training Steps: 199000
Train Loss: 0.000129505, averaged to 8.10416466183e-08
Test Loss: 6.01553e-05, averaged to 9.92662139066e-08


Training Steps: 200000
Train Loss: 0.000129503, averaged to 8.1040781517e-08
Test Loss: 6.01657e-05, averaged to 9.92832931966e-08


Training Steps: 201000
Train Loss: 0.000129502, averaged to 8.10399437347e-08
Test Loss: 6.01757e-05, averaged to 9.92999102351e-08


Training Steps: 202000
Train Loss: 0.0001295, averaged to 8.10391059523e-08
Test Loss: 6.0186e-05, averaged to 9.93167674042e-08


Training Steps: 203000
Train Loss: 0.000129499, averaged to 8.10383592332e-08
Test Loss: 6.01959e-05, averaged to 9.93332403644e-08


Training Steps: 204000
Train Loss: 0.000129498, averaged to 8.10375669825e-08
Test Loss: 6.02057e-05, averaged to 9.93493291155e-08


Training Steps: 205000
Train Loss: 0.000129497, averaged to 8.10368293698e-08
Test Loss: 6.02153e-05, averaged to 9.93651056969e-08


Training Steps: 206000
Train Loss: 0.000129496, averaged to 8.10361281824e-08
Test Loss: 6.02236e-05, averaged to 9.93789432235e-08


Training Steps: 207000
Train Loss: 0.000129495, averaged to 8.10354452077e-08
Test Loss: 6.02324e-05, averaged to 9.93933570637e-08


Training Steps: 208000
Train Loss: 0.000129494, averaged to 8.10347622329e-08
Test Loss: 6.02411e-05, averaged to 9.94078009201e-08


Training Steps: 209000
Train Loss: 0.000129493, averaged to 8.10341794278e-08
Test Loss: 6.02492e-05, averaged to 9.94211942051e-08


Training Steps: 210000
Train Loss: 0.000129492, averaged to 8.1033551091e-08
Test Loss: 6.02568e-05, averaged to 9.94336509807e-08


Training Steps: 211000
Train Loss: 0.000129491, averaged to 8.10329682859e-08
Test Loss: 6.02643e-05, averaged to 9.944607774e-08


Training Steps: 212000
Train Loss: 0.00012949, averaged to 8.10323763745e-08
Test Loss: 6.02716e-05, averaged to 9.94581563099e-08


Training Steps: 213000
Train Loss: 0.000129489, averaged to 8.1031784463e-08
Test Loss: 6.02787e-05, averaged to 9.94698266578e-08


Training Steps: 214000
Train Loss: 0.000129488, averaged to 8.10313018275e-08
Test Loss: 6.02857e-05, averaged to 9.94812988979e-08


Training Steps: 215000
Train Loss: 0.000129487, averaged to 8.10307463414e-08
Test Loss: 6.02927e-05, averaged to 9.94929632425e-08


Training Steps: 216000
Train Loss: 0.000129486, averaged to 8.10302454933e-08
Test Loss: 6.02993e-05, averaged to 9.95037991365e-08


Training Steps: 217000
Train Loss: 0.000129486, averaged to 8.10297264325e-08
Test Loss: 6.03057e-05, averaged to 9.95142928443e-08


Training Steps: 218000
Train Loss: 0.000129485, averaged to 8.1029243797e-08
Test Loss: 6.03118e-05, averaged to 9.95244023432e-08


Training Steps: 219000
Train Loss: 0.000129481, averaged to 8.10268488322e-08
Test Loss: 6.03015e-05, averaged to 9.95074971479e-08


Training Steps: 220000
Train Loss: 0.000129473, averaged to 8.10221681786e-08
Test Loss: 6.02862e-05, averaged to 9.94821873812e-08


Training Steps: 221000
Train Loss: 0.000129467, averaged to 8.10179792669e-08
Test Loss: 6.02816e-05, averaged to 9.94745392211e-08


Training Steps: 222000
Train Loss: 0.00012946, averaged to 8.10140726513e-08
Test Loss: 6.02793e-05, averaged to 9.94708592194e-08


Training Steps: 223000
Train Loss: 0.000129455, averaged to 8.10105211826e-08
Test Loss: 6.02797e-05, averaged to 9.94714895623e-08


Training Steps: 224000
Train Loss: 0.000129449, averaged to 8.10071245216e-08
Test Loss: 6.02807e-05, averaged to 9.94730804276e-08


Training Steps: 225000
Train Loss: 0.000129444, averaged to 8.10039919441e-08
Test Loss: 6.02828e-05, averaged to 9.94765983411e-08


Training Steps: 226000
Train Loss: 0.00012944, averaged to 8.10010688122e-08
Test Loss: 6.02859e-05, averaged to 9.9481731133e-08


Training Steps: 227000
Train Loss: 0.000129435, averaged to 8.09983369132e-08
Test Loss: 6.02894e-05, averaged to 9.94874222286e-08


Training Steps: 228000
Train Loss: 0.000129431, averaged to 8.09957780345e-08
Test Loss: 6.02932e-05, averaged to 9.94936956409e-08


Training Steps: 229000
Train Loss: 0.000129427, averaged to 8.09933830697e-08
Test Loss: 6.02974e-05, averaged to 9.95007254646e-08


Training Steps: 230000
Train Loss: 0.000129424, averaged to 8.09911246999e-08
Test Loss: 6.03019e-05, averaged to 9.95080254353e-08


Training Steps: 231000
Train Loss: 0.00012942, averaged to 8.09889938187e-08
Test Loss: 6.03067e-05, averaged to 9.9516051801e-08


Training Steps: 232000
Train Loss: 0.000129417, averaged to 8.09870086388e-08
Test Loss: 6.03116e-05, averaged to 9.95240721636e-08


Training Steps: 233000
Train Loss: 0.000129414, averaged to 8.09851509475e-08
Test Loss: 6.03162e-05, averaged to 9.9531660291e-08


Training Steps: 234000
Train Loss: 0.000129411, averaged to 8.09833934258e-08
Test Loss: 6.0321e-05, averaged to 9.95396386306e-08


Training Steps: 235000
Train Loss: 0.000129409, averaged to 8.09816996484e-08
Test Loss: 6.03262e-05, averaged to 9.95482293034e-08


Training Steps: 236000
Train Loss: 0.000129406, averaged to 8.09801606787e-08
Test Loss: 6.03318e-05, averaged to 9.95573902863e-08


Training Steps: 237000
Train Loss: 0.000129404, averaged to 8.09786763469e-08
Test Loss: 6.03384e-05, averaged to 9.95682802097e-08


Training Steps: 238000
Train Loss: 0.000129402, averaged to 8.09773012911e-08
Test Loss: 6.03449e-05, averaged to 9.95790140481e-08


Training Steps: 239000
Train Loss: 0.0001294, averaged to 8.09759899796e-08
Test Loss: 6.03512e-05, averaged to 9.95894537266e-08


Training Steps: 240000
Train Loss: 0.000129398, averaged to 8.09747788377e-08
Test Loss: 6.03575e-05, averaged to 9.95998994083e-08


Training Steps: 241000
Train Loss: 0.000129396, averaged to 8.09735859085e-08
Test Loss: 6.03637e-05, averaged to 9.9610026917e-08


Training Steps: 242000
Train Loss: 0.000129394, averaged to 8.09724567235e-08
Test Loss: 6.03701e-05, averaged to 9.96205746542e-08


Training Steps: 243000
Train Loss: 0.000129392, averaged to 8.09714368146e-08
Test Loss: 6.03769e-05, averaged to 9.96318788029e-08


Training Steps: 244000
Train Loss: 0.000129391, averaged to 8.09704715436e-08
Test Loss: 6.03831e-05, averaged to 9.96421203736e-08


Training Steps: 245000
Train Loss: 0.000129389, averaged to 8.09695518043e-08
Test Loss: 6.03898e-05, averaged to 9.96531363655e-08


Training Steps: 246000
Train Loss: 0.000129388, averaged to 8.09686867029e-08
Test Loss: 6.03961e-05, averaged to 9.9663600057e-08


Training Steps: 247000
Train Loss: 0.000129387, averaged to 8.09679126649e-08
Test Loss: 6.0403e-05, averaged to 9.96748801926e-08


Training Steps: 248000
Train Loss: 0.000129385, averaged to 8.09670748826e-08
Test Loss: 6.04094e-05, averaged to 9.96855479952e-08


Training Steps: 249000
Train Loss: 0.000129384, averaged to 8.09663828015e-08
Test Loss: 6.04161e-05, averaged to 9.9696515961e-08


66000	0.000133115	5.702e-05
65000	0.000133156	5.70204e-05
67000	0.000133081	5.70211e-05
64000	0.000133204	5.70218e-05
68000	0.00013305	5.70235e-05
63000	0.000133256	5.70264e-05
69000	0.000133024	5.70264e-05
62000	0.00013329	5.70274e-05
61000	0.000133329	5.70297e-05
70000	0.000132999	5.703e-05
71000	0.000132977	5.70334e-05
60000	0.000133374	5.70344e-05
72000	0.000132958	5.70347e-05
73000	0.00013294	5.70363e-05
74000	0.000132923	5.70381e-05
75000	0.000132907	5.70397e-05
76000	0.000132893	5.70415e-05
77000	0.000132879	5.70428e-05
78000	0.000132865	5.70437e-05
59000	0.000133427	5.70439e-05
79000	0.000132853	5.70446e-05
80000	0.00013284	5.70453e-05
81000	0.000132829	5.70456e-05
82000	0.000132818	5.7046e-05
83000	0.000132807	5.70464e-05
58000	0.000133488	5.70564e-05
57000	0.000133559	5.70718e-05
54000	0.000133872	5.70887e-05
56000	0.000133645	5.70915e-05
55000	0.000133749	5.70924e-05
53000	0.000133935	5.71e-05
52000	0.00013397	5.71037e-05
51000	0.000134008	5.71075e-05
50000	0.000134048	5.71115e-05
102000	0.00013161	5.71161e-05
49000	0.000134091	5.71164e-05
48000	0.000134138	5.71217e-05
47000	0.000134188	5.71283e-05
101000	0.000131728	5.71334e-05
46000	0.000134243	5.71362e-05
45000	0.000134302	5.71455e-05
44000	0.000134367	5.7156e-05
103000	0.000131502	5.71562e-05
43000	0.000134437	5.71693e-05
84000	0.000132615	5.71754e-05
42000	0.000134514	5.71858e-05
100000	0.0001318	5.7193e-05
99000	0.000131847	5.71938e-05
98000	0.000131896	5.71947e-05
97000	0.000131947	5.71971e-05
96000	0.000132001	5.72003e-05
104000	0.000131401	5.72043e-05
41000	0.0001346	5.72081e-05
95000	0.00013206	5.72092e-05
85000	0.000132555	5.72201e-05
40000	0.000134695	5.72366e-05
86000	0.000132509	5.72436e-05
94000	0.000132138	5.72487e-05
105000	0.000131307	5.72543e-05
39000	0.000134804	5.72747e-05
87000	0.000132432	5.72921e-05
106000	0.000131219	5.73055e-05
38000	0.000134929	5.73265e-05
88000	0.000132396	5.73502e-05
89000	0.00013237	5.73815e-05
37000	0.000135075	5.73959e-05
90000	0.000132349	5.74034e-05
107000	0.00013114	5.74082e-05
91000	0.000132332	5.7422e-05
92000	0.000132316	5.74385e-05
93000	0.000132302	5.74526e-05
36000	0.000135251	5.74906e-05
108000	0.000130978	5.75736e-05
35000	0.000135467	5.76157e-05
109000	0.000130895	5.77384e-05
33000	0.000135965	5.77514e-05
34000	0.000135741	5.77642e-05
26000	0.000137277	5.7778e-05
32000	0.000136155	5.77783e-05
25000	0.000137279	5.77943e-05
21000	0.000137376	5.78193e-05
24000	0.0001373	5.78206e-05
31000	0.000136316	5.78288e-05
22000	0.000137336	5.78502e-05
23000	0.000137329	5.78523e-05
20000	0.000137741	5.78552e-05
19000	0.000137741	5.78611e-05
110000	0.000130828	5.78676e-05
30000	0.00013649	5.7882e-05
18000	0.000137749	5.78909e-05
29000	0.000136675	5.79357e-05
27000	0.000137116	5.79616e-05
111000	0.00013077	5.79846e-05
28000	0.000136876	5.79854e-05
112000	0.000130718	5.80927e-05
7000	0.000138576	5.8176e-05
113000	0.000130672	5.81921e-05
3000	0.000138852	5.82362e-05
4000	0.000138852	5.82362e-05
5000	0.000138852	5.82362e-05
6000	0.000138852	5.82362e-05
114000	0.000130631	5.82838e-05
17000	0.000138086	5.83431e-05
16000	0.000138087	5.83503e-05
8000	0.000138457	5.83535e-05
9000	0.000138457	5.83535e-05
115000	0.000130593	5.83683e-05
15000	0.000138093	5.83899e-05
116000	0.000130558	5.84457e-05
1000	0.000139929	5.84688e-05
2000	0.000139929	5.84688e-05
10000	0.000138393	5.85164e-05
117000	0.000130526	5.85173e-05
11000	0.000138337	5.85828e-05
118000	0.000130496	5.85832e-05
14000	0.00013821	5.85848e-05
140000	0.000129998	5.85946e-05
141000	0.000129966	5.86012e-05
142000	0.000129938	5.86394e-05
119000	0.000130469	5.86435e-05
12000	0.000138329	5.8649e-05
13000	0.000138329	5.8649e-05
143000	0.000129912	5.86827e-05
120000	0.000130443	5.86989e-05
144000	0.000129888	5.87277e-05
121000	0.000130419	5.87508e-05
145000	0.000129866	5.87722e-05
122000	0.000130397	5.87978e-05
139000	0.000130057	5.88163e-05
146000	0.000129845	5.88172e-05
123000	0.000130375	5.88415e-05
147000	0.000129825	5.88612e-05
124000	0.000130355	5.8882e-05
148000	0.000129807	5.89047e-05
125000	0.000130336	5.89193e-05
149000	0.00012979	5.89472e-05
126000	0.000130318	5.89543e-05
127000	0.000130302	5.89864e-05
150000	0.000129773	5.8989e-05
128000	0.000130285	5.90161e-05
151000	0.000129758	5.90293e-05
129000	0.00013027	5.90443e-05
152000	0.000129743	5.90697e-05
130000	0.000130255	5.90699e-05
131000	0.000130241	5.90941e-05
153000	0.00012973	5.91085e-05
132000	0.000130228	5.91172e-05
133000	0.000130215	5.91386e-05
154000	0.000129717	5.91476e-05
134000	0.000130203	5.91588e-05
135000	0.000130191	5.91772e-05
155000	0.000129705	5.91857e-05
136000	0.00013018	5.9195e-05
137000	0.00013017	5.92118e-05
156000	0.000129694	5.92233e-05
138000	0.000130159	5.92275e-05
157000	0.000129683	5.92596e-05
158000	0.000129673	5.92947e-05
159000	0.000129664	5.93291e-05
160000	0.000129655	5.93631e-05
161000	0.000129646	5.93961e-05
162000	0.000129638	5.94288e-05
163000	0.00012963	5.94605e-05
164000	0.000129623	5.94906e-05
165000	0.000129616	5.95203e-05
166000	0.00012961	5.95487e-05
167000	0.000129603	5.95767e-05
168000	0.000129598	5.96044e-05
169000	0.000129592	5.96309e-05
170000	0.000129587	5.96568e-05
171000	0.000129582	5.9682e-05
172000	0.000129577	5.97059e-05
173000	0.000129572	5.97295e-05
174000	0.000129568	5.97524e-05
175000	0.000129564	5.97747e-05
176000	0.00012956	5.97967e-05
177000	0.000129556	5.98179e-05
178000	0.000129552	5.98391e-05
179000	0.000129549	5.98587e-05
180000	0.000129546	5.98786e-05
181000	0.000129543	5.98971e-05
182000	0.00012954	5.99158e-05
183000	0.000129537	5.9934e-05
184000	0.000129534	5.99508e-05
185000	0.000129531	5.99674e-05
186000	0.000129529	5.99829e-05
187000	0.000129527	5.99985e-05
188000	0.000129524	6.00144e-05
189000	0.000129522	6.0029e-05
190000	0.00012952	6.00433e-05
191000	0.000129518	6.00576e-05
192000	0.000129516	6.00708e-05
193000	0.000129514	6.0084e-05
194000	0.000129512	6.00974e-05
195000	0.000129511	6.01098e-05
196000	0.000129509	6.01216e-05
197000	0.000129508	6.01333e-05
198000	0.000129506	6.01448e-05
199000	0.000129505	6.01553e-05
200000	0.000129503	6.01657e-05
201000	0.000129502	6.01757e-05
202000	0.0001295	6.0186e-05
203000	0.000129499	6.01959e-05
204000	0.000129498	6.02057e-05
205000	0.000129497	6.02153e-05
206000	0.000129496	6.02236e-05
207000	0.000129495	6.02324e-05
208000	0.000129494	6.02411e-05
209000	0.000129493	6.02492e-05
210000	0.000129492	6.02568e-05
211000	0.000129491	6.02643e-05
212000	0.00012949	6.02716e-05
213000	0.000129489	6.02787e-05
222000	0.00012946	6.02793e-05
223000	0.000129455	6.02797e-05
224000	0.000129449	6.02807e-05
221000	0.000129467	6.02816e-05
225000	0.000129444	6.02828e-05
214000	0.000129488	6.02857e-05
226000	0.00012944	6.02859e-05
220000	0.000129473	6.02862e-05
227000	0.000129435	6.02894e-05
215000	0.000129487	6.02927e-05
228000	0.000129431	6.02932e-05
229000	0.000129427	6.02974e-05
216000	0.000129486	6.02993e-05
219000	0.000129481	6.03015e-05
230000	0.000129424	6.03019e-05
217000	0.000129486	6.03057e-05
231000	0.00012942	6.03067e-05
232000	0.000129417	6.03116e-05
218000	0.000129485	6.03118e-05
233000	0.000129414	6.03162e-05
234000	0.000129411	6.0321e-05
235000	0.000129409	6.03262e-05
236000	0.000129406	6.03318e-05
237000	0.000129404	6.03384e-05
238000	0.000129402	6.03449e-05
239000	0.0001294	6.03512e-05
240000	0.000129398	6.03575e-05
241000	0.000129396	6.03637e-05
242000	0.000129394	6.03701e-05
243000	0.000129392	6.03769e-05
244000	0.000129391	6.03831e-05
245000	0.000129389	6.03898e-05
246000	0.000129388	6.03961e-05
247000	0.000129387	6.0403e-05
248000	0.000129385	6.04094e-05
249000	0.000129384	6.04161e-05
